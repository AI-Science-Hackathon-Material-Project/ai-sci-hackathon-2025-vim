{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c558ea-7f5e-4b4d-a339-7a89e6778290",
   "metadata": {},
   "source": [
    "This jupyter gives you a simple example of how you should use the Simulated Network (asynchronous) environment. This environment is not meant as a training ground of your algorithms, but only to check whether or not your algorithm can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 2 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,state_dim=state_dim)\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b3b3f7-8dc7-455f-bf05-df02d2ef95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([5 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the action space dimensions\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75680da-4bd1-40b1-a3fe-607e070a5c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the state space dimensions\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can now for example get a random action:\n",
    "action = env.action_space.sample()\n",
    "action\n",
    "# This action can then be applied to the environment with:\n",
    "# state, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a4cc22-d672-490f-93c6-d98b3ca82de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [3 0]\n",
      "Reward: 1, Avg. reward: 1.0\n",
      "State: [-1.          0.         -0.38089071  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [-0.5        -0.42798381  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.3333333333333333\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [0.5        0.         0.34304681 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [ 0.         -0.31125525  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 1, Avg. reward: 0.16666666666666666\n",
      "State: [-0.5        -0.38903238 -0.13283862  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 1, Avg. reward: 0.2857142857142857\n",
      "State: [-0.5         0.         -0.29250335  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.25\n",
      "State: [ 0.5        -0.36749026  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.1111111111111111\n",
      "State: [0.         0.28641201 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.2\n",
      "State: [ 0.5        -0.32798589  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: -1, Avg. reward: 0.09090909090909091\n",
      "State: [-1.         -0.23477507  0.2489395   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.25\n",
      "State: [ 0.5        -0.48402554 -0.1971773   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.38461538461538464\n",
      "State: [ 0.         -0.33770237 -0.30676094  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.35714285714285715\n",
      "State: [-0.5      -0.462781  0.        0.      ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.4666666666666667\n",
      "State: [ 0.5        -0.30801039 -0.22419875  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.5\n",
      "State: [-0.5        -0.33428954  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.4117647058823529\n",
      "State: [-1.          0.32430037  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.4444444444444444\n",
      "State: [-0.5         0.35390738  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.42105263157894735\n",
      "State: [ 0.5        -0.37362082  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [-0.5        -0.31463752  0.13780856  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.38095238095238093\n",
      "State: [-1.         -0.30066834  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.36363636363636365\n",
      "State: [-0.5       -0.4101768  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.391304347826087\n",
      "State: [-0.5        -0.29407521  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.375\n",
      "State: [-1.         -0.39862155  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 2, Avg. reward: 0.44\n",
      "State: [-0.5        0.        -0.2816363  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4230769230769231\n",
      "State: [-0.5        -0.34449528  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.4444444444444444\n",
      "State: [ 0.          0.         -0.05601497  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.39285714285714285\n",
      "State: [-1.          0.          0.38713721  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 0, Avg. reward: 0.3793103448275862\n",
      "State: [ 0.5        -0.25903331  0.02927433  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.4\n",
      "State: [ 0.          0.         -0.18962526  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.3548387096774194\n",
      "State: [0.5        0.         0.32233444 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.40625\n",
      "State: [ 0.5        -0.37805393 -0.21372011  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.3939393939393939\n",
      "State: [-0.5        -0.43454119  0.2645888   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.4117647058823529\n",
      "State: [-0.5       -0.4338005  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.42857142857142855\n",
      "State: [ 0.5        -0.33857683  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 0, Avg. reward: 0.4166666666666667\n",
      "State: [ 0.5        -0.35893463  0.26195971  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.3783783783783784\n",
      "State: [0.         0.         0.13290832 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.39473684210526316\n",
      "State: [ 0.5        -0.39523544  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.41025641025641024\n",
      "State: [ 0.5         0.         -0.02111445  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: -1, Avg. reward: 0.36585365853658536\n",
      "State: [ 0.         -0.22578116  0.31789601  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.3333333333333333\n",
      "State: [-1.          0.          0.24813941  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.3488372093023256\n",
      "State: [-0.5         0.         -0.19905416  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.3409090909090909\n",
      "State: [ 0.5        -0.40026647  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.3333333333333333\n",
      "State: [-1.         -0.41010413  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.32608695652173914\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.2978723404255319\n",
      "State: [0.         0.         0.10831889 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: 0.2916666666666667\n",
      "State: [-1.         -0.0667894  -0.40993714  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: 1, Avg. reward: 0.30612244897959184\n",
      "State: [ 0.         -0.46688443  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.32\n",
      "State: [-1.         -0.48934677  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [-1.         -0.33179539  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.36538461538461536\n",
      "State: [-0.5        -0.4243325  -0.24876014  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.37735849056603776\n",
      "State: [-0.5        -0.22178933  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.3888888888888889\n",
      "State: [-1.         -0.31806817  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.41818181818181815\n",
      "State: [ 0.5        -0.29650963 -0.08534682  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.4107142857142857\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.40350877192982454\n",
      "State: [ 0.5        -0.40818991  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.41379310344827586\n",
      "State: [ 0.5        -0.42225071 -0.23162696  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.423728813559322\n",
      "State: [-0.5         0.         -0.13805158  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.45\n",
      "State: [-1.         -0.31719488 -0.17123718  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 0, Avg. reward: 0.4426229508196721\n",
      "State: [ 0.         -0.29354433  0.16641346  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.46774193548387094\n",
      "State: [ 0.        -0.4042989 -0.212517   0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.47619047619047616\n",
      "State: [ 0.5        -0.26075762  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.453125\n",
      "State: [0.5        0.         0.31483212 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.47692307692307695\n",
      "State: [-1.         -0.4107988  -0.11953796  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.48484848484848486\n",
      "State: [ 0.         -0.32155657  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.47761194029850745\n",
      "State: [ 0.5        -0.39134513  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.47058823529411764\n",
      "State: [ 0.5        -0.34949962  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.463768115942029\n",
      "State: [-0.5        -0.42365468  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.44285714285714284\n",
      "State: [0.5        0.         0.34451161 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.43661971830985913\n",
      "State: [-0.5        -0.45824324  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.4166666666666667\n",
      "State: [0.         0.41269717 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.3972602739726027\n",
      "State: [0.5        0.32826515 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.3918918918918919\n",
      "State: [-0.5        -0.43357338  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.38666666666666666\n",
      "State: [-1.         -0.46747335  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: -1, Avg. reward: 0.3684210526315789\n",
      "State: [-1.         -0.39160706  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.37662337662337664\n",
      "State: [ 0.         -0.33331616  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.38461538461538464\n",
      "State: [ 0.5         0.         -0.27424145  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 0, Avg. reward: 0.379746835443038\n",
      "State: [ 0.         -0.24720895  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.375\n",
      "State: [ 0.         -0.46261775  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.35802469135802467\n",
      "State: [0.         0.32654549 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.35365853658536583\n",
      "State: [ 0.5        -0.46212221  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.3373493975903614\n",
      "State: [0.         0.42934267 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.3333333333333333\n",
      "State: [-1.         -0.43589438  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 0, Avg. reward: 0.32941176470588235\n",
      "State: [ 0.5        -0.38687099  0.22253968  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.32558139534883723\n",
      "State: [-1.         -0.28802248  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [ 0.         -0.47317334  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.3181818181818182\n",
      "State: [0.5        0.33453906 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 0, Avg. reward: 0.3146067415730337\n",
      "State: [ 0.         -0.36679204  0.08702674  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.32222222222222224\n",
      "State: [-1.         -0.30327858  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.32967032967032966\n",
      "State: [ 0.         -0.33783919  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: 1, Avg. reward: 0.33695652173913043\n",
      "State: [ 0.        -0.4151492  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.3225806451612903\n",
      "State: [0.        0.5067992 0.        0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.3191489361702128\n",
      "State: [-0.5        -0.42077372  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.3157894736842105\n",
      "State: [-0.5        -0.43122345  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 0, Avg. reward: 0.3125\n",
      "State: [ 0.         -0.33854547  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 2, Avg. reward: 0.32989690721649484\n",
      "State: [ 0.         -0.37497847  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.32653061224489793\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.31313131313131315\n",
      "State: [-1.          0.46015511  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.31\n",
      "State: [-0.5        -0.38435779  0.26618888  0.        ]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
