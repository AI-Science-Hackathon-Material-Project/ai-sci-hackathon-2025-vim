{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3952e9f6-751e-4180-91e7-df4f94107ba3",
   "metadata": {},
   "source": [
    "This jupyter notebook teaches you how to create a dynamic (i.e. trained) state reduction object and how to train and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the state reduction function\n",
    "from StateReduction.DynamicStatePCA import DynamicStatePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 2 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of the state reduction function\n",
    "state = DynamicStatePCA(state_dim=state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e153a0-a5c9-4873-950b-26cf395f3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,\n",
    "                            state_dim=state_dim,\n",
    "                            state_object=state) # Use the state object\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3224ae1-8590-4fa6-99e3-ca65ce51e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 responses to random stimuli for training\n",
    "spikes    = []\n",
    "elecs     = []\n",
    "for i in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    spikes.append(info['spikes'])\n",
    "    elecs.append(info['elecs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8164cc17-2264-405e-90c2-d80ad74c0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your state function (Notice, you are doing this through your environment)\n",
    "env.fit(spikes,elecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 2.0\n",
      "State: [[-0.05002577  0.68119573  0.08358294 -0.37334839]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 2.0\n",
      "State: [[ 0.19708191  0.10839806 -0.04300881 -0.07469544]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 2.0\n",
      "State: [[-0.17907816 -0.11408751  0.12798183  0.15684715]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 1.25\n",
      "State: [[ 0.22173571  0.06398802 -0.16820762 -0.47395109]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 1.2\n",
      "State: [[ 0.37860242  0.55761332 -0.37355568  0.12470878]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 1.1666666666666667\n",
      "State: [[ 0.04117189 -0.04786208  0.68071281 -0.05883711]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [[-0.36990782  0.31910571 -0.01911934  0.02381673]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.875\n",
      "State: [[ 0.11091313  0.38084845 -0.42844443 -0.16301975]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 3, Avg. reward: 1.1111111111111112\n",
      "State: [[ 0.21145616 -0.08162552 -0.56813225  0.14264258]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [[-0.07834977  0.27861862 -0.06921121 -0.16814691]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.9090909090909091\n",
      "State: [[0.17719515 0.27560889 0.05182268 0.07646107]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.8333333333333334\n",
      "State: [[ 0.03486015  0.32116995  0.12865525 -0.27405411]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.7692307692307693\n",
      "State: [[ 0.00428286  0.18393372  0.10321463 -0.3205839 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.7142857142857143\n",
      "State: [[ 0.06804579  0.20440201 -0.0365733  -0.00068855]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.6666666666666666\n",
      "State: [[ 0.19115161 -0.0478931   0.11079905 -0.10497567]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 0, Avg. reward: 0.625\n",
      "State: [[ 0.19174264 -0.01154387  0.1821002  -0.35248426]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.5294117647058824\n",
      "State: [[ 0.29710302  0.38910288 -0.14762731 -0.04409716]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.5555555555555556\n",
      "State: [[-0.00474884  0.31559239  0.40723925  0.07349033]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.631578947368421\n",
      "State: [[ 0.16656132 -0.09480082 -0.1242372   0.07590157]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 3, Avg. reward: 0.75\n",
      "State: [[ 0.05802111  0.52823328 -0.26345592 -0.5109072 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.8095238095238095\n",
      "State: [[-0.11019142  0.27021088 -0.26025088  0.14385405]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 2, Avg. reward: 0.8636363636363636\n",
      "State: [[-0.26953432  0.19409248  0.24487267 -0.02384568]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.782608695652174\n",
      "State: [[-0.18893572  0.19280662  0.06218214  0.56269154]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.7916666666666666\n",
      "State: [[ 0.10863367  0.62630528  0.45012857 -0.08783097]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.76\n",
      "State: [[ 0.06804579  0.20440201 -0.0365733  -0.00068855]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.7307692307692307\n",
      "State: [[-0.02515909  0.18745372 -0.00213048  0.07097024]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.7037037037037037\n",
      "State: [[ 0.15376129  0.44039864 -0.26016085  0.16661455]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: -1, Avg. reward: 0.6428571428571429\n",
      "State: [[ 0.2869642   0.0069847  -0.03266912 -0.20656583]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.5862068965517241\n",
      "State: [[ 0.55616075  0.23347257 -0.06427699 -0.1152467 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.5333333333333333\n",
      "State: [[-0.0983301   0.00675647 -0.01971609  0.23132941]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.5161290322580645\n",
      "State: [[ 0.23146008  0.210003   -0.21937606 -0.34889012]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [[-0.04247924  0.26545005 -0.07383745  0.21365433]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 0, Avg. reward: 0.48484848484848486\n",
      "State: [[0.19960857 0.25555604 0.15400249 0.12429697]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.5\n",
      "State: [[0.30036822 0.21370657 0.21499522 0.22792023]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.45714285714285713\n",
      "State: [[ 0.06751655  0.15507077 -0.14709934  0.00717279]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.4722222222222222\n",
      "State: [[-0.40529221  0.27498855  0.25475377  0.17956957]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.4594594594594595\n",
      "State: [[ 0.10142607  0.37307816 -0.27434214 -0.08176142]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.47368421052631576\n",
      "State: [[0.0734681  0.14101733 0.03720796 0.10441732]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -2, Avg. reward: 0.41025641025641024\n",
      "State: [[-0.00187377  0.10326759 -0.04478696  0.01273639]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [[-0.28716032  0.16795142  0.24151193 -0.01866594]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.36585365853658536\n",
      "State: [[ 0.25906544  0.0637813   0.42348104 -0.32611715]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.38095238095238093\n",
      "State: [[ 9.44873116e-02  2.90840081e-04 -2.35139662e-02 -3.34527602e-01]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.3953488372093023\n",
      "State: [[-0.11769837 -0.04865262  0.16045266 -0.12773294]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.4090909090909091\n",
      "State: [[ 0.52156323 -0.03901335 -0.13741952 -0.13027961]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.4444444444444444\n",
      "State: [[-0.24325763  0.4898474   0.21306471 -0.36778785]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.43478260869565216\n",
      "State: [[-0.27822489  0.34179094 -0.08154155 -0.06370718]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.425531914893617\n",
      "State: [[-0.09647431  0.61294651  0.12946125 -0.05217458]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.4375\n",
      "State: [[-0.06009159  0.08603105  0.16173259  0.12175618]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.46938775510204084\n",
      "State: [[0.06619575 0.20781713 0.02706679 0.0081833 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.44\n",
      "State: [[ 0.22173571  0.06398802 -0.16820762 -0.47395109]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.45098039215686275\n",
      "State: [[-0.29193387  0.42604597 -0.03350201  0.20809251]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.4423076923076923\n",
      "State: [[ 0.10719275  0.04906229 -0.04127312 -0.32810941]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.4339622641509434\n",
      "State: [[-0.14139623  0.22341887  0.10813533  0.07238416]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.46296296296296297\n",
      "State: [[-0.16744351  0.22320341 -0.43152395  0.18642107]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.45454545454545453\n",
      "State: [[ 0.09650535  0.43156737 -0.23035744 -0.27458075]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.44642857142857145\n",
      "State: [[ 0.06233439  0.01522398 -0.02202238  0.11724826]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.43859649122807015\n",
      "State: [[-0.18146175  0.39703084 -0.29300536 -0.14077801]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.4482758620689655\n",
      "State: [[ 0.30733037  0.21505786 -0.31367656 -0.30226069]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.4406779661016949\n",
      "State: [[ 0.04784906  0.17306733 -0.14155919 -0.14292094]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.45\n",
      "State: [[ 0.10587103  0.13738609  0.29528907 -0.02614265]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.4262295081967213\n",
      "State: [[ 0.21828183 -0.24037858  0.11077864 -0.028875  ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.43548387096774194\n",
      "State: [[-0.03442052  0.42385527 -0.34933049 -0.09101938]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.42857142857142855\n",
      "State: [[-0.18229659  0.23660724 -0.34069672 -0.19868205]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.40625\n",
      "State: [[ 0.01967533 -0.14899484  0.23090877 -0.08585827]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.4153846153846154\n",
      "State: [[-0.33937546  0.03327968  0.17785142 -0.11484388]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4090909090909091\n",
      "State: [[-0.18146175  0.39703084 -0.29300536 -0.14077801]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.40298507462686567\n",
      "State: [[ 0.06863681  0.24075125  0.03472785 -0.24819714]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.39705882352941174\n",
      "State: [[ 0.06863681  0.24075125  0.03472785 -0.24819714]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.4057971014492754\n",
      "State: [[0.29525236 0.01174093 0.13749916 0.33213608]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [[ 0.06804579  0.20440201 -0.0365733  -0.00068855]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.4084507042253521\n",
      "State: [[ 0.03502131  0.22608021 -0.28004217 -0.28869382]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.4166666666666667\n",
      "State: [[ 0.06451479  0.050401    0.05989973 -0.40715927]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.3972602739726027\n",
      "State: [[ 0.16030248  0.34093006 -0.36969514  0.06315216]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.3918918918918919\n",
      "State: [[-0.14044475  0.39376483 -0.4163863   0.1681816 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.38666666666666666\n",
      "State: [[-0.19045619  0.43020056 -0.18851644 -0.24384192]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.3815789473684211\n",
      "State: [[-0.18146175  0.39703084 -0.29300536 -0.14077801]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.37662337662337664\n",
      "State: [[-0.09804202  0.08089841  0.22023712 -0.1751338 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.38461538461538464\n",
      "State: [[-0.08174458  0.31752049 -0.24009345  0.09430429]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.4050632911392405\n",
      "State: [[ 0.20220788  0.40364544 -0.02200769  0.19506485]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 1, Avg. reward: 0.4125\n",
      "State: [[ 0.23971663  0.34952577 -0.10157007 -0.04503182]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.41975308641975306\n",
      "State: [[-0.50639672  0.25655471  0.12080011 -0.10023018]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.4146341463414634\n",
      "State: [[ 0.19353088  0.50773938 -0.15096364  0.30376607]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 1, Avg. reward: 0.42168674698795183\n",
      "State: [[ 0.10201709  0.4094274  -0.20304099 -0.32927001]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.42857142857142855\n",
      "State: [[-0.11865018 -0.06490738 -0.33169763  0.20540451]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.4117647058823529\n",
      "State: [[ 0.00525459 -0.13610503 -0.02564182  0.01929448]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.4186046511627907\n",
      "State: [[ 0.25536145 -0.06795879  0.0627316  -0.10146757]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.40229885057471265\n",
      "State: [[-0.13104883  0.52309168 -0.25827519 -0.65637916]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 0, Avg. reward: 0.3977272727272727\n",
      "State: [[-0.05022686  0.00137297 -0.07719898  0.01959356]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.39325842696629215\n",
      "State: [[-0.24070183  0.18473877  0.47841157 -0.18217895]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.4111111111111111\n",
      "State: [[ 0.43464531  0.37029302 -0.1420786  -0.16115378]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: -1, Avg. reward: 0.3956043956043956\n",
      "State: [[ 0.24379642  0.55862599 -0.18021289  0.20606235]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.40217391304347827\n",
      "State: [[ 0.19721825  0.23505115 -0.40152715 -0.38949504]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.3978494623655914\n",
      "State: [[-0.23203995  0.31823363 -0.39051646  0.1159954 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 1, Avg. reward: 0.40425531914893614\n",
      "State: [[-0.09274391  0.05612108  0.06247609 -0.2907072 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.4\n",
      "State: [[ 0.24239971  0.18644763  0.22202212 -0.06187882]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.40625\n",
      "State: [[-0.20524853  0.12071728 -0.12754212 -0.33801485]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.3917525773195876\n",
      "State: [[ 0.00434416  0.02965659  0.14137323 -0.21581886]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 1, Avg. reward: 0.3979591836734694\n",
      "State: [[ 0.19474114  0.06992202 -0.29543521 -0.11835095]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.3939393939393939\n",
      "State: [[-0.02661968  0.36332919  0.13924807  0.03425042]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.39\n",
      "State: [[ 0.21263192  0.28471814 -0.21501138 -0.07442116]]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ecccb-a597-4505-b3a2-6881380908e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
